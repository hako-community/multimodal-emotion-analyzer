# multimodal-emotion-analyzer
# ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ„Ÿæƒ…åˆ†æã‚·ã‚¹ãƒ†ãƒ 

**è¡¨æƒ…èªè­˜ Ã— éŸ³å£°èªè­˜ ã«ã‚ˆã‚‹çµ±åˆæ„Ÿæƒ…åˆ†æ**

OpenAI Whisper + MediaPipe ã‚’ä½¿ç”¨ã—ãŸã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆè¤‡æ•°ã®å…¥åŠ›å½¢å¼ï¼‰ã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªæ„Ÿæƒ…ãƒ»çŠ¶æ…‹åˆ†æã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

## æ¦‚è¦

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ä»¥ä¸‹ã®2ã¤ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆå…¥åŠ›å½¢å¼ï¼‰ã‚’çµ±åˆã—ã¦ã€äººã®æ„Ÿæƒ…ã‚„å¿ƒç†çŠ¶æ…‹ã‚’ã‚ˆã‚Šæ­£ç¢ºã«æŠŠæ¡ã—ã¾ã™ï¼š

1. **è¡¨æƒ…èªè­˜** (MediaPipe + æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«)
   - 7ç¨®é¡ã®æ„Ÿæƒ…ã‚’æ¤œå‡ºï¼ˆæ€’ã‚Šã€å«Œæ‚ªã€ææ€–ã€å¹¸ã›ã€æ‚²ã—ã¿ã€é©šãã€ä¸­ç«‹ï¼‰
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ï¼ˆ30-60 FPSï¼‰

2. **éŸ³å£°èªè­˜** (OpenAI Whisper)
   - ç™ºè©±å†…å®¹ã®ãƒ†ã‚­ã‚¹ãƒˆåŒ–
   - å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
   - è¨€èªè‡ªå‹•æ¤œå‡º

3. **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆåˆ†æ**
   - è¡¨æƒ…ã¨ç™ºè¨€å†…å®¹ã®ç›¸é–¢åˆ†æ
   - çŸ›ç›¾æ¤œå‡ºï¼ˆä¾‹ï¼šç¬‘é¡”ã ãŒãƒã‚¬ãƒ†ã‚£ãƒ–ãªç™ºè¨€ï¼‰
   - ç·åˆçš„ãªæ„Ÿæƒ…ãƒ»ã‚¹ãƒˆãƒ¬ã‚¹çŠ¶æ…‹ã®è©•ä¾¡

## ä¸»ãªæ©Ÿèƒ½

### ğŸ­ è¡¨æƒ…èªè­˜
- **7ç¨®é¡ã®è¡¨æƒ…åˆ†é¡**: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral
- **é«˜é€Ÿå‡¦ç†**: CPUç’°å¢ƒã§30-60 FPS
- **ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°**: æ™‚ç³»åˆ—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§å®‰å®šã—ãŸçµæœ

### ğŸ¤ éŸ³å£°èªè­˜  
- **é«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—**: Whisperã«ã‚ˆã‚‹å¤šè¨€èªå¯¾å¿œ
- **ç™ºè©±ç‰¹å¾´åˆ†æ**:
  - ç™ºè©±é€Ÿåº¦ï¼ˆå˜èª/ç§’ï¼‰
  - æ²ˆé»™ãƒ»ãƒãƒ¼ã‚ºã®æ¤œå‡º
  - ç™ºè©±æ™‚é–“æ¯”ç‡

### ğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆæ„Ÿæƒ…åˆ†æ
- **æ¥µæ€§åˆ¤å®š**: ãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–/ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
- **æ„Ÿæƒ…åˆ†é¡**: å–œã³ã€æ€’ã‚Šã€æ‚²ã—ã¿ã€ææ€–ãªã©
- **è¨€èªçš„ç‰¹å¾´**:
  - å¦å®šèªã®æ¤œå‡º
  - ãƒ•ã‚£ãƒ©ãƒ¼ï¼ˆãˆã£ã¨ã€ã‚ã®ã€ãªã©ï¼‰ã®åˆ†æ
  - ç–‘å•æ–‡ãƒ»ç¹°ã‚Šè¿”ã—ã®æ¤œå‡º

### ğŸ”„ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆ
- **çŸ›ç›¾æ¤œå‡º**:
  - ä½œã‚Šç¬‘ã„ï¼ˆç¬‘é¡” Ã— ãƒã‚¬ãƒ†ã‚£ãƒ–ç™ºè¨€ï¼‰
  - æ„Ÿæƒ…ã®æŠ‘åˆ¶ï¼ˆæ€’ã‚Š Ã— ç©ã‚„ã‹ãªç™ºè¨€ï¼‰
  - è™šå½ï¼ˆæ‚²ã—ã„è¡¨æƒ… Ã— ã€Œå¤§ä¸ˆå¤«ã€ç™ºè¨€ï¼‰

- **ç·åˆè©•ä¾¡**:
  - ã‚¹ãƒˆãƒ¬ã‚¹ã‚¹ã‚³ã‚¢ (0-100)
  - ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢ (0-100)
  - ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0)

- **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:
  - çŠ¶æ…‹ã«å¿œã˜ãŸå…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
  - ä¼‘æ†©ã‚„ã‚µãƒãƒ¼ãƒˆã®ææ¡ˆ

## ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
multimodal-emotion-analyzer/
â”œâ”€â”€ multimodal_app.py              # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ emotion_detector_mediapipe.py  # MediaPipeç‰ˆè¡¨æƒ…èªè­˜
â”œâ”€â”€ config.yaml                    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ requirements.txt               # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â”‚
â”œâ”€â”€ modules/                       # ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ whisper_recognizer.py     # WhisperéŸ³å£°èªè­˜
â”‚   â”œâ”€â”€ text_sentiment.py         # ãƒ†ã‚­ã‚¹ãƒˆæ„Ÿæƒ…åˆ†æ
â”‚   â””â”€â”€ multimodal_analyzer.py    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆåˆ†æ
â”‚
â”œâ”€â”€ models/                        # æ¤œå‡ºãƒ»èªè­˜ãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ detector.py
â”‚
â”œâ”€â”€ utils/                         # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â”œâ”€â”€ visualizer.py             # å¯è¦–åŒ–
â”‚   â””â”€â”€ logger.py                 # ãƒ­ã‚°
â”‚
â””â”€â”€ trained_models/                # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    â”œâ”€â”€ emotion_models/           # è¡¨æƒ…èªè­˜ãƒ¢ãƒ‡ãƒ«
    â””â”€â”€ mediapipe/                # MediaPipeãƒ¢ãƒ‡ãƒ«
```

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### 1. å¿…è¦ãªç’°å¢ƒ
- Python 3.8-3.12
- ffmpegï¼ˆéŸ³å£°å‡¦ç†ç”¨ï¼‰

### 2. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

ä¸»ãªä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼š
- `openai-whisper`: éŸ³å£°èªè­˜
- `mediapipe`: é¡”æ¤œå‡º
- `opencv-python`: ç”»åƒå‡¦ç†
- `tensorflow/keras`: è¡¨æƒ…èªè­˜
- `numpy`, `scipy`: æ•°å€¤è¨ˆç®—

### 3. ffmpegã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**Windows (Chocolatey)**:
```bash
choco install ffmpeg
```

**Windows (Scoop)**:
```bash
scoop install ffmpeg
```

**Ubuntu/Debian**:
```bash
sudo apt update && sudo apt install ffmpeg
```

## ä½¿ã„æ–¹

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

#### 1. è¡¨æƒ…èªè­˜ã®ã¿ï¼ˆã‚«ãƒ¡ãƒ©ã‹ã‚‰ï¼‰

```bash
python multimodal_app.py
```

#### 2. å‹•ç”» + éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã§çµ±åˆåˆ†æ

```bash
python multimodal_app.py --video video.mp4 --audio audio.wav
```

#### 3. ã‚«ãƒ¡ãƒ©IDæŒ‡å®š

```bash
python multimodal_app.py --camera 1
```

#### 4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š

```bash
python multimodal_app.py --config my_config.yaml
```

### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ | ä¾‹ |
|-----------|------|-----|
| `--config` | è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | `--config config.yaml` |
| `--camera` | ã‚«ãƒ¡ãƒ©ID | `--camera 0` |
| `--video` | å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | `--video input.mp4` |
| `--audio` | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | `--audio speech.wav` |

### Whisperå˜ä½“ã§ã®éŸ³å£°èªè­˜

```python
from modules.whisper_recognizer import WhisperRecognizer

# åˆæœŸåŒ–
recognizer = WhisperRecognizer(model_name="base", language="ja")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èªè­˜
result = recognizer.transcribe_file("audio.mp3", word_timestamps=True)

print(f"èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ: {result['text']}")
print(f"è¨€èª: {result['language']}")

# éŸ³å£°ç‰¹å¾´åˆ†æ
features = recognizer.analyze_speech_features(result)
print(f"ç™ºè©±é€Ÿåº¦: {features['speech_rate']:.2f} å˜èª/ç§’")
print(f"ãƒãƒ¼ã‚ºæ•°: {features['num_pauses']}")
```

### ãƒ†ã‚­ã‚¹ãƒˆæ„Ÿæƒ…åˆ†æ

```python
from modules.text_sentiment import TextSentimentAnalyzer

analyzer = TextSentimentAnalyzer(language="ja")

text = "ä»Šæ—¥ã¯ç–²ã‚ŒãŸã‘ã©æ¥½ã—ã‹ã£ãŸã§ã™"
result = analyzer.analyze_comprehensive(text)

print(f"æ¥µæ€§: {result['sentiment']['polarity']}")
print(f"æ”¯é…çš„æ„Ÿæƒ…: {result['sentiment']['dominant_emotion']}")
print(f"çŠ¶æ…‹: {result['overall_state']['state']}")
```

### ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆåˆ†æ

```python
from modules.multimodal_analyzer import MultiModalAnalyzer

analyzer = MultiModalAnalyzer()

# è¡¨æƒ… + éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã§åˆ†æ
result = analyzer.analyze(
    emotion_data={"emotion": "happy", "confidence": 0.89},
    speech_data={"text": "ä»Šæ—¥ã¯æœ¬å½“ã«å¬‰ã—ã„ã§ã™ï¼"}
)

print(f"ç·åˆçŠ¶æ…‹: {result['overall_state']['state']}")
print(f"ã‚¹ãƒˆãƒ¬ã‚¹ã‚¹ã‚³ã‚¢: {result['overall_state']['stress_score']}")
print(f"çŸ›ç›¾æ•°: {len(result['contradictions'])}")
print(f"ä¿¡é ¼åº¦: {result['trust_score']}")
```

## è¨­å®š

`config.yaml`ã§ä»¥ä¸‹ã®é …ç›®ã‚’è¨­å®šã§ãã¾ã™ï¼š

### Whisperè¨­å®š

```yaml
whisper:
  model: "base"          # tiny, base, small, medium, large, turbo
  device: "cpu"          # cpu or cuda
  language: "ja"         # ja (æ—¥æœ¬èª), en (è‹±èª), auto (è‡ªå‹•)
  word_timestamps: true
```

### é¡”æ¤œå‡ºè¨­å®š

```yaml
face_detection:
  model: "mediapipe"     # mediapipe, yolov8, haarcascade
  mediapipe:
    min_detection_confidence: 0.5
```

### è¡¨æƒ…èªè­˜è¨­å®š

```yaml
emotion_recognition:
  model: "original"      # original, hsemotion, fer
  smoothing:
    enabled: true
    window_size: 6
```

## å¿œç”¨ä¾‹

### 1. ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- é•·æœŸçš„ãªæ„Ÿæƒ…å¤‰åŒ–ã®è¿½è·¡
- ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«ã®å¯è¦–åŒ–
- ã†ã¤å‚¾å‘ã®æ—©æœŸç™ºè¦‹

### 2. ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ
- ä¼šè­°ã®é›°å›²æ°—æ¸¬å®š
- è©±è€…ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆè©•ä¾¡
- ãƒãƒ¼ãƒ ã®å¿ƒç†çš„å®‰å…¨æ€§ã®è©•ä¾¡

### 3. ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ
- é¡§å®¢æº€è¶³åº¦ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¸¬å®š
- ä¸æº€ã®æ—©æœŸæ¤œå‡º
- å¯¾å¿œå“è³ªã®æ”¹å–„

### 4. æ•™è‚²ãƒ»å­¦ç¿’æ”¯æ´
- å­¦ç¿’è€…ã®ç†è§£åº¦æŠŠæ¡
- é›†ä¸­åº¦ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
- å€‹åˆ¥ã‚µãƒãƒ¼ãƒˆã®æœ€é©åŒ–

## å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿

### çµ±åˆåˆ†æçµæœã®æ§‹é€ 

```python
{
    "timestamp": 1234567890.123,
    "emotion_data": {
        "emotion": "happy",
        "confidence": 0.89,
        "bbox": (x1, y1, x2, y2)
    },
    "speech_data": {
        "text": "ä»Šæ—¥ã¯å¬‰ã—ã„ã§ã™",
        "language": "ja"
    },
    "text_sentiment": {
        "polarity": "POSITIVE",
        "score": 0.85,
        "dominant_emotion": "joy"
    },
    "contradictions": [
        {
            "type": "fake_smile",
            "severity": "medium",
            "description": "ç¬‘é¡”ã ãŒã€ç™ºè¨€å†…å®¹ã¯ãƒã‚¬ãƒ†ã‚£ãƒ–"
        }
    ],
    "overall_state": {
        "state": "è‰¯å¥½",
        "stress_score": 25.5,
        "positive_score": 75.3,
        "contradiction_count": 1
    },
    "trust_score": 0.85,
    "recommendations": [
        "è‰¯å¥½ãªçŠ¶æ…‹ã§ã™ã€‚ç¾çŠ¶ã‚’ç¶­æŒã—ã¾ã—ã‚‡ã†"
    ]
}
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### MediaPipeã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼

```bash
pip uninstall mediapipe
pip install mediapipe==0.10.14
```

### Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒé…ã„

åˆå›å®Ÿè¡Œæ™‚ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ~150MBï½1.5GBï¼‰ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚
ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆ`tiny`ã‚„`base`ï¼‰ã®ä½¿ç”¨ã‚’æ¨å¥¨ï¼š

```yaml
whisper:
  model: "base"  # tiny (39M), base (74M), small (244M)
```

### GPUå¯¾å¿œ

CUDAãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆï¼š

```yaml
whisper:
  device: "cuda"
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### å‡¦ç†é€Ÿåº¦ï¼ˆç›®å®‰ï¼‰

| ãƒ¢ãƒ‡ãƒ« | CPU (Intel i5) | GPU (GTX 1060) |
|--------|---------------|----------------|
| è¡¨æƒ…èªè­˜ | 30-60 FPS | 100+ FPS |
| Whisper (base) | 2-5x realtime | 10-20x realtime |

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

- è¡¨æƒ…èªè­˜: ~500MB
- Whisper (base): ~1GB
- ç·ãƒ¡ãƒ¢ãƒª: ~2-3GB

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ä»¥ä¸‹ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼š

- [OpenAI Whisper](https://github.com/openai/whisper) - MIT License
- [MediaPipe](https://github.com/google/mediapipe) - Apache License 2.0
- ãã®ä»–ã®ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¤ã„ã¦ã¯requirements.txtã‚’å‚ç…§

## å‚è€ƒè³‡æ–™

- [Whisperãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://github.com/openai/whisper)
- [MediaPipeãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://developers.google.com/mediapipe)
- [ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ„Ÿæƒ…èªè­˜ã®ç ”ç©¶è«–æ–‡](https://arxiv.org/abs/2212.04356)

## ä»Šå¾Œã®æ‹¡å¼µ

- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒã‚¤ã‚¯å…¥åŠ›å¯¾å¿œ
- [ ] éŸ³éŸ¿ç‰¹å¾´é‡ã®è¿½åŠ åˆ†æï¼ˆãƒ”ãƒƒãƒã€éŸ³é‡ãªã©ï¼‰
- [ ] è¦–ç·šè¿½è·¡ã®çµ±åˆ
- [ ] é•·æœŸçš„ãªå‚¾å‘åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- [ ] Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¿½åŠ 

## ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. `logs/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
2. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³
3. Pythonç’°å¢ƒï¼ˆ`python --version`ï¼‰

---

**é–‹ç™º**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ„Ÿæƒ…åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  
**æ›´æ–°æ—¥**: 2026å¹´1æœˆ8æ—¥
